{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stein Variational Gradient Descent (SVGD)\n",
    "\n",
    "### References\n",
    "- [Qiang Liu, Dilin Wang, \"Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm\", NIPS, 2016.](https://arxiv.org/abs/1608.04471)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "color = {'orange': '#FF4B00', 'blue': '#005AFF', 'green': '#03AF7A', 'purple': '#990099'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Ground Truth Probablity Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture Gaussian Distribution\n",
    "class MixtureGaussianDistribution:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension: int, # the dimension of the data : writing it as D below\n",
    "        num_components: int, # how many gaussian components in the mixture? : writing it as K below\n",
    "        weight_array: np.ndarray, # the weights of the gaussian components : size is (K,)\n",
    "        mu_array: np.ndarray, # the means of the gaussian components : size is (K, D)\n",
    "        cov_array: np.ndarray, # the standard deviations of the gaussian components : size is (K, D, D)\n",
    "    ) -> None:\n",
    "        # get the number of components\n",
    "        self.pdf_name = \"Mixture Gaussian Distribution\"\n",
    "        self.dimension = dimension # D\n",
    "        self.num_components = num_components # K\n",
    "\n",
    "        # check if the size of weight_array is (K,)\n",
    "        if not(weight_array.shape == (self.num_components,)):\n",
    "            raise ValueError(\"The size of the weight_array must be (num_components,)\")\n",
    "        # check if the size of mu_array is (K, D)\n",
    "        if not(mu_array.shape == (self.num_components, self.dimension)):\n",
    "            raise ValueError(\"The size of the mu_array must be (num_components, dimension)\")\n",
    "        # check if the size of cov_array is (K, D, D)\n",
    "        if not(cov_array.shape == (self.num_components, self.dimension, self.dimension)):\n",
    "            raise ValueError(\"The size of the cov_array must be (num_components, dimension, dimension)\")\n",
    "        # check if the sum of the weights is 1\n",
    "        if not(np.abs(np.sum(weight_array) - 1) < 1e-10):\n",
    "            raise ValueError(\"The sum of the weights must be 1\")\n",
    "\n",
    "        # store the parameters\n",
    "        self.weight_array = weight_array\n",
    "        self.mu_array = mu_array\n",
    "        self.cov_array = cov_array\n",
    "\n",
    "        # obtain precision_array from cov_array\n",
    "        self.precision_array = np.zeros((self.num_components, self.dimension, self.dimension))\n",
    "        for k in range(self.num_components):\n",
    "            self.precision_array[k] = np.linalg.inv(self.cov_array[k])\n",
    "\n",
    "    def gaussian(self, x: np.ndarray, mu: np.ndarray, sigma: np.ndarray) -> float:\n",
    "        # calculate the probability of the Gaussian distribution\n",
    "        return 1 / np.sqrt((2 * np.pi) ** self.dimension * np.linalg.det(sigma)) * np.exp(-0.5 * (x - mu).T @ np.linalg.inv(sigma) @ (x - mu))\n",
    "\n",
    "    def mix_gaussian(self, x: np.ndarray) -> float:\n",
    "        # calculate the probability\n",
    "        prob = 0\n",
    "        for k in range(self.num_components):\n",
    "            prob += self.weight_array[k] * self.gaussian(x, self.mu_array[k], self.cov_array[k])\n",
    "        return prob\n",
    "\n",
    "    def dln_mix_gaussian(self, x: np.ndarray) -> np.ndarray:\n",
    "        # calculate the derivative of the probability\n",
    "        ddx_mix_gaussian = np.zeros(self.dimension)\n",
    "        for k in range(self.num_components):\n",
    "            ddx_mix_gaussian += self.weight_array[k] * self.gaussian(x, self.mu_array[k], self.cov_array[k]) * (-1.0 * self.precision_array[k] @ (x - self.mu_array[k]))\n",
    "        return ddx_mix_gaussian / self.mix_gaussian(x)\n",
    "\n",
    "    def prob(self, x: np.ndarray) -> float:\n",
    "        # return p(x)\n",
    "        return self.mix_gaussian(x)\n",
    "    \n",
    "    def dlnprob(self, x: np.ndarray) -> np.ndarray:\n",
    "        # return nabla ln p(x)\n",
    "        return self.dln_mix_gaussian(x)\n",
    "    \n",
    "    def plot_2d(self, \n",
    "                idx_select=[0, 1], # 2-dim .e. x[idx_select[0]] and x[idx_select[1]] are plotted\n",
    "                x_min=-10, x_max=10, y_min=-10, y_max=10, res_x=100, res_y=100, # axis range and resolution\n",
    "                levels=10, dpi=100, save_path=None # other settings\n",
    "        ):\n",
    "        # plot the contour of the probability density function\n",
    "        fig, ax = plt.subplots(dpi=dpi)\n",
    "        x = np.linspace(x_min, x_max, res_x)\n",
    "        y = np.linspace(y_min, y_max, res_y)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros((res_x, res_y))\n",
    "        for i in range(res_x):\n",
    "            for j in range(res_y):\n",
    "                Z[i, j] = self.prob(np.array([X[i, j], Y[i, j]]))\n",
    "        ax.contour(X, Y, Z, levels=levels, cmap='viridis')\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(f\"{self.pdf_name}\", fontsize=16)\n",
    "        ax.set_xlabel(f\"x_{idx_select[0]}\", fontsize=14)\n",
    "        ax.set_ylabel(f\"x_{idx_select[1]}\", fontsize=14)\n",
    "        # save figure if necessary\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "# run test\n",
    "gmm_test = MixtureGaussianDistribution(\n",
    "    dimension=2,\n",
    "    num_components=3,\n",
    "    weight_array=np.array([0.3, 0.3, 0.4]),\n",
    "    mu_array=np.array([[-4, 3], [4, -3], [5, 5]]),\n",
    "    cov_array=np.array([[[4, 2], [2, 5]], [[6, 0], [0, 4]], [[3.0, 0.0], [0.0, 3.0]]])\n",
    ")\n",
    "gmm_test.plot_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVGD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVGD class\n",
    "class SVGD:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_particle: int, # the dimension of a particle\n",
    "        num_particles: int, # the number of particles\n",
    "        gd_step_size: float, # the step size of the gradient descent\n",
    "        dlnprob: callable, # the gradient of the log probability\n",
    "        particles_init: np.ndarray, # the initial particles: size is (num_particles, dim_particle)\n",
    "    ):\n",
    "        # load parameters\n",
    "        self.dim_particle = dim_particle\n",
    "        self.num_particles = num_particles\n",
    "        self.gd_step_size = gd_step_size\n",
    "        self.dlnprob = dlnprob\n",
    "        \n",
    "        # initialization\n",
    "        self.reset(particles_init=particles_init)\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        particles_init: np.ndarray, # the initial particles: size is (num_particles, dim_particle)\n",
    "    ):\n",
    "        # check if the size of particles_init is (num_particles, dim_particle)\n",
    "        if not(particles_init.shape == (self.num_particles, self.dim_particle)):\n",
    "            raise ValueError(\"The size of particles_init must be (num_particles, dim_particle)\")\n",
    "\n",
    "        # load the initial particles\n",
    "        self.particles = particles_init\n",
    "\n",
    "        # reset the iteration count\n",
    "        self._iter_count = 0\n",
    "\n",
    "    def kernel(\n",
    "        self,\n",
    "        x_a: np.ndarray,\n",
    "        x_b: np.ndarray,\n",
    "        sqh = 0.5 # if sqh>0, use the value, if sqh<0 use median trick mensioned in the svgd paper.\n",
    "    ):\n",
    "        # TODO: implement median trick of sqh (when sqh < 0)\n",
    "        return np.exp(-1.0 * np.linalg.norm(x_a - x_b, 2) / sqh**2)\n",
    "\n",
    "    def d_kernel(\n",
    "        self,\n",
    "        x_a: np.ndarray,\n",
    "        x_b: np.ndarray,\n",
    "        sqh = 0.5 # if sqh>0, use the value, if sqh<0 use median trick mensioned in the svgd paper.\n",
    "    ):\n",
    "        # TODO: implement median trick of sqh (when sqh < 0)\n",
    "        return (-1.0 / sqh**2) * (x_a - x_b) * np.exp(-1.0 * np.linalg.norm(x_a - x_b, 2) / sqh**2)\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        n_iter: int, # the number of iterations\n",
    "    ):\n",
    "        # start the timer\n",
    "        time_ms_calc_start = time.perf_counter() * 1000.0\n",
    "\n",
    "        # update the particles for n_iter times using SVGD\n",
    "        for l in range(n_iter):\n",
    "            self._iter_count += 1 # increment the total iteration count\n",
    "            for i in range(self.num_particles):\n",
    "                x_i_l = self.particles[i, :] # load x_i_l\n",
    "                x_i_l_plus_1 = x_i_l # initialize x_i_l_plus_1\n",
    "                for j in range(self.num_particles):\n",
    "                    x_j_l = self.particles[j, :]\n",
    "                    kxx = self.kernel(x_j_l, x_i_l)\n",
    "                    dlnpx = self.dlnprob(x_j_l)\n",
    "                    dkxx = self.d_kernel(x_j_l, x_i_l)\n",
    "                    x_i_l_plus_1 += (1.0 / self.num_particles) * kxx * dlnpx + dkxx\n",
    "                self.particles[i, :] = x_i_l_plus_1\n",
    "\n",
    "        # stop the timer\n",
    "        time_ms_calc_end = time.perf_counter() * 1000.0\n",
    "\n",
    "        # return the updated particles and the calculation time [ms]\n",
    "        return self.particles.copy(), (time_ms_calc_end - time_ms_calc_start), self._iter_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizer class\n",
    "class Visualizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        pdf: callable,\n",
    "        view_x_min: float, view_x_max: float,\n",
    "        view_y_min: float, view_y_max: float,\n",
    "        dpi: int = 100, res_x: int = 100, res_y: int = 100, figsize: list[int] = [7, 7],\n",
    "        make_animation: bool = False,\n",
    "    ) -> None:\n",
    "        # load parameters\n",
    "        self.pdf = pdf\n",
    "        self.view_x_min, self.view_x_max, self.res_x = view_x_min, view_x_max, res_x\n",
    "        self.view_y_min, self.view_y_max, self.res_y = view_y_min, view_y_max, res_y\n",
    "        self.dpi = dpi\n",
    "        self.figsize = figsize\n",
    "\n",
    "        # initialize figure\n",
    "        self.__init_fig()\n",
    "\n",
    "        # initialize animation if necessary\n",
    "        self.make_animation = make_animation\n",
    "        if self.make_animation:\n",
    "            self.__init_animation()\n",
    "\n",
    "    def __init_fig(self):\n",
    "        # make figure\n",
    "        self.fig, self.ax = plt.subplots(1, 1, dpi=self.dpi, figsize=self.figsize)\n",
    "\n",
    "        # prepare grid_x, grid_y\n",
    "        self.grid_x = np.linspace(self.view_x_min, self.view_x_max, self.res_x)\n",
    "        self.grid_y = np.linspace(self.view_y_min, self.view_y_max, self.res_y)\n",
    "        self.mesh_x, self.mesh_y = np.meshgrid(self.grid_x, self.grid_y)\n",
    "        self.mesh_z = np.zeros((self.res_x, self.res_y))\n",
    "        for i in range(self.res_x):\n",
    "            for j in range(self.res_y):\n",
    "                self.mesh_z[i, j] = self.pdf(np.array([self.mesh_x[i, j], self.mesh_y[i, j]]))\n",
    "\n",
    "        # graph layout settings\n",
    "        self.ax.set_xlim(self.view_x_min, self.view_x_max)\n",
    "        self.ax.set_ylim(self.view_y_min, self.view_y_max)\n",
    "        self.ax.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
    "        self.ax.tick_params(bottom=False, left=False, right=False, top=False)\n",
    "        self.ax.set_aspect('equal')\n",
    "\n",
    "    def plot_2d(\n",
    "        self,\n",
    "        init_fig: bool = True,\n",
    "        iter_count: int = None,\n",
    "        particles: np.ndarray = None, # set np.ndarray if scatter plot is necessary. size: (?, 2)\n",
    "    ) -> None:\n",
    "        # initialize figure if necessary\n",
    "        if init_fig:\n",
    "            self.__init_fig()\n",
    "\n",
    "        # visualize the results\n",
    "        self.ax.contour(self.mesh_x, self.mesh_y, self.mesh_z, cmap='viridis')\n",
    "\n",
    "        # set iter_count as title if necessary\n",
    "        if iter_count is not None:\n",
    "            self.ax.set_title(f\"iteration: {iter_count}\")\n",
    "        \n",
    "        # plot particles if necessary\n",
    "        if particles is not None:\n",
    "            self.ax.scatter(particles[:, 0], particles[:, 1], color=color[\"blue\"])\n",
    "\n",
    "        # show figure\n",
    "        plt.show()\n",
    "\n",
    "    def __init_animation(\n",
    "        self\n",
    "    ) -> None:\n",
    "        # clear animation frames\n",
    "        self.anim_frames = []\n",
    "\n",
    "    def add_animation_frame(\n",
    "        self,\n",
    "        particles: np.ndarray,\n",
    "        iter_count: int = None,\n",
    "        init_anim = False\n",
    "    ) -> None:\n",
    "        # initialize animation if necessary\n",
    "        if init_anim:\n",
    "            self.__init_animation()\n",
    "\n",
    "        # add contents to the latest frame\n",
    "        frame = [self.ax.contour(self.mesh_x, self.mesh_y, self.mesh_z, cmap='viridis')]\n",
    "        frame += [self.ax.scatter(particles[:, 0], particles[:, 1], color=color[\"blue\"])]\n",
    "\n",
    "        # add title text\n",
    "        info_text = f\"Bayesian Inference with SVGD\"\n",
    "        frame += [self.ax.text(0.5, 1.07, info_text, ha='center', transform=self.ax.transAxes, fontsize=14, fontfamily='monospace')]\n",
    "\n",
    "\n",
    "        # add text info if necessary\n",
    "        if iter_count is not None:\n",
    "            # draw the information text\n",
    "            info_text = f\"iteration: {iter_count: 5d}\"\n",
    "            frame += [self.ax.text(0.5, 1.02, info_text, ha='center', transform=self.ax.transAxes, fontsize=14, fontfamily='monospace')]\n",
    "\n",
    "        # append frame\n",
    "        self.anim_frames.append(frame)\n",
    "\n",
    "    def save_animation(self, filename, interval=500, movie_writer=\"ffmpeg\") -> None:\n",
    "        # save animation of the recorded frames (ffmpeg required)\n",
    "        ani = ArtistAnimation(self.fig, self.anim_frames, interval=interval, blit=True)\n",
    "        ani.save(filename, writer=movie_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bayesian Inference with SVGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ground truth probability density function (pdf) and its logaritmic gradient\n",
    "ground_truth_pdf = MixtureGaussianDistribution(\n",
    "    dimension=2,\n",
    "    num_components=3,\n",
    "    weight_array=np.array([0.3, 0.3, 0.4]),\n",
    "    mu_array=np.array([[-4, 3], [4, -3], [5, 5]]),\n",
    "    cov_array=np.array([[[4, 2], [2, 5]], [[6, 0], [0, 4]], [[3.0, 0.0], [0.0, 3.0]]])\n",
    ")\n",
    "\n",
    "# set parameters and initialize svgd\n",
    "NUM_PARTICLES = 50\n",
    "inferrer = SVGD(\n",
    "    dim_particle=2,\n",
    "    num_particles=NUM_PARTICLES,\n",
    "    gd_step_size=5.0,\n",
    "    dlnprob=ground_truth_pdf.dlnprob,\n",
    "    particles_init=np.random.randn(NUM_PARTICLES, 2)\n",
    ")\n",
    "\n",
    "# initialize visualizer\n",
    "vis = Visualizer(\n",
    "    pdf = ground_truth_pdf.prob,\n",
    "    view_x_min = -10.0,\n",
    "    view_x_max = +10.0,\n",
    "    view_y_min = -10.0,\n",
    "    view_y_max = +10.0,\n",
    "    make_animation=True,\n",
    ")\n",
    "\n",
    "# run bayesian infere50nce to approximate the ground truth pdf using svgd\n",
    "for _ in range(50):\n",
    "    # update svgd particles\n",
    "    particles_updated, calc_time, current_iter_count = inferrer.update(n_iter=10)\n",
    "    print(f\"iteration count: {current_iter_count:04d}\")\n",
    "\n",
    "    # [FOR DEBUG] plot figure\n",
    "    # vis.plot_2d(init_fig=True, iter_count=current_iter_count, particles=particles_updated)\n",
    "\n",
    "    # add animation frame\n",
    "    vis.add_animation_frame(particles_updated, iter_count=current_iter_count)\n",
    "\n",
    "# save animation\n",
    "vis.save_animation(interval=100, filename=\"svgd.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
